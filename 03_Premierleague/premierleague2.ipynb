{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>A Win/Lose prediction model of Premierleague games</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='premier.jpg' width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- EDA\n",
    "- Preprocessing\n",
    "- Modeling\n",
    "- Optimization\n",
    "- Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def category_to_ohe(train_col, test_col):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_col)\n",
    "    \n",
    "    labeled_train_col = le.transform(train_col)\n",
    "    labeled_train_col = labeled_train_col.reshape(len(labeled_train_col),1)\n",
    "    \n",
    "    labeled_test_col = le.transform(test_col)\n",
    "    labeled_test_col = labeled_test_col.reshape(len(labeled_test_col),1)\n",
    "    \n",
    "    return labeled_train_col, labeled_test_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Modeling\n",
    "\n",
    "# 3.1 조건부 확률기반 생성모형\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis # QDA\n",
    "from sklearn.naive_bayes import * # Naive basesian\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # LDA\n",
    "\n",
    "\n",
    "# 3.2 조건부 확률기반 판별모형\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# 3.3 모형결합 (Ensenble)\n",
    "from sklearn.ensemble import VotingClassifier # voting\n",
    "from sklearn.ensemble import BaggingClassifier # bagging\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier # random Forest\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier # AdaBoost\n",
    "from sklearn.ensemble import GradientBoostingClassifier # GradientBoost\n",
    "import xgboost # xgboost\n",
    "\n",
    "\n",
    "# 3.4 판별함수 모형\n",
    "from sklearn.linear_model import Perceptron # perceptron\n",
    "from sklearn.linear_model import SGDClassifier # SGD\n",
    "from sklearn.svm import SVC # support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Optimizer\n",
    "from sklearn.model_selection import validation_curve # validation curve\n",
    "from sklearn.model_selection import GridSearchCV # gridseach\n",
    "from sklearn.model_selection import ParameterGrid # ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Evaluation\n",
    "from sklearn.metrics import * # make confusion matrix\n",
    "from sklearn.preprocessing import label_binarize # ROC curve\n",
    "from sklearn.metrics import auc # AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "print('train shape :', train.shape) # 12 - 16 season\n",
    "print('test shape :', test.shape) # 17 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check information\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique\n",
    "print('train unique 갯수')\n",
    "for i in range(14):\n",
    "    print('{} : {}개'.format(train.columns[i], len(set(train[train.columns[i]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_data\n",
    "print('win 횟수 :', len(train[train['Result'] == 0]))\n",
    "print('lose 횟수 :', len(train[train['Result'] == 1]))\n",
    "print('draw 횟수 :', len(train[train['Result'] == 2]))\n",
    "\n",
    "sns.countplot(x = 'Result', data = train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature countplot\n",
    "plt.figure(figsize=(20, 18))\n",
    "subplots_adjust(hspace = 0.3)\n",
    "\n",
    "for i in range(1, 12+1) :\n",
    "    plt.subplot(4, 3, i)\n",
    "    sns.barplot(x = train['Result'], y = train[train.columns[i]],)\n",
    "    plt.title('{} countplot plot'.format(train.columns[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature boxplot\n",
    "plt.figure(figsize=(20, 18))\n",
    "subplots_adjust(hspace = 0.3)\n",
    "\n",
    "for i in range(1, 12+1) :\n",
    "    plt.subplot(4, 3, i)\n",
    "    sns.boxplot(x = train['Result'], y = train[train.columns[i]], data = train)\n",
    "    plt.title('{} box plot'.format(train.columns[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자화\n",
    "train.groupby('Result').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "result0 = train[train['Result'] == 0]\n",
    "result1 = train[train['Result'] == 1]\n",
    "result2 = train[train['Result'] == 2]\n",
    "\n",
    "# feature scatter plot\n",
    "plt.figure(figsize=(20, 20))\n",
    "subplots_adjust(hspace = 0.3)\n",
    "\n",
    "for i in range(1, 12+1) :\n",
    "    plt.subplot(4, 3, i)\n",
    "    plt.plot(result0[result0.columns[i]], 'ro', alpha = 0.5, markersize = 3)\n",
    "    plt.plot(result1[result1.columns[i]], 'bo', alpha = 0.3, markersize = 3)\n",
    "    plt.plot(result2[result2.columns[i]], 'go', alpha = 0.2, markersize = 3)\n",
    "    plt.title('{} scatter plot'.format(result0.columns[i]))\n",
    "    plt.xlabel(result0.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation\n",
    "correlation = train.drop(['Team', 'Result'], axis = 1)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation.corr(), annot=True, linewidths=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "category = ['Home']\n",
    "continuous = ['Possession', 'Shots', 'Touches', 'Passes',\n",
    "              'Tackles', 'Clearances','SOT', 'Corners', 'Offsides', 'Goal', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train/test data\n",
    "\n",
    "train_cols, test_cols = [], []\n",
    "\n",
    "# category\n",
    "for cat in category:\n",
    "    train_tok, test_tok = category_to_ohe(train[cat],test[cat])\n",
    "    train_cols.append(train_tok)\n",
    "    test_cols.append(test_tok)    \n",
    "\n",
    "# continuous\n",
    "for con in continuous:\n",
    "    train_cols.append(train[con].values.reshape(len(train),1))\n",
    "    test_cols.append(test[con].values.reshape(len(test),1))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack train/test data\n",
    "X_train = np.hstack(tuple(each for each in train_cols))\n",
    "X_test = np.hstack(tuple(each for each in test_cols))\n",
    "y_train = train['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 조건부 확률 모형 : 각 클래스가 정답일 조건부 확률을 계산\n",
    "\n",
    "    - 조건부 확률기반 생성모형 : 베이즈 정리를 사용\n",
    "\n",
    "        - LDA (linear discriminant analysis)\n",
    "        - QDA (Quadratic Discriminanat Analysis)\n",
    "        - 나이브 베이지안 (Naive Bayes)\n",
    "    \n",
    "    - 조건부 확률기반 판별모형 :  직접 조건부 확률 함수를 추정\n",
    "    \n",
    "        - 로지스틱 회귀 (Logistic Regression)\n",
    "        - 의사결정나무 (Descision Tree)\n",
    "        - KNN (K Nearest Neighbor)\n",
    "        \n",
    "        \n",
    "- 판별함수 모형 : 경계면을 찾아서 데이터가 어느 위치에 있는지 계산\n",
    "\n",
    "    - 퍼셉트론 (Perceptron)\n",
    "    - 서포트 벡터 머신 (Support Vector Machine)\n",
    "    - 신경망 (Neural Network)  \n",
    "    \n",
    "    \n",
    "- 모형결합 (Ensemble) : 복수의 예측모형을 결합하여 더 나은 성능을 예측하려는 시도\n",
    "\n",
    "    - 취합 방법론 : 사용할 모형의 집합이 이미 결정되어 있음\n",
    "        \n",
    "        - 다수결 (Majority voting)\n",
    "        - 배깅 (Bagging)\n",
    "        - 랜덤 포레스트 (Random Forest)\n",
    "        \n",
    "    - 부스팅 방법론 : 사용할 모형을 점진적으로 늘림\n",
    "    \n",
    "        - 에이다 부스트 (AdaBoost)\n",
    "        - 그레디언트 부스트 (Gradient Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 조건부 확률모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 조건부 확률기반 생성 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA (linear discriminant analysis)\n",
    "model = LinearDiscriminantAnalysis(n_components=3, solver=\"svd\", \n",
    "        store_covariance=True).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDA (Quadratic Discriminanat Analysis)\n",
    "model = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Naive bayesian - Multinomial\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive bayesian - Gaussian\n",
    "model = GaussianNB().fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 조건부 확률기반 판별모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression : 사용 X (종속변수가 이항분포를 따라야함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descision Tree\n",
    "model = DecisionTreeClassifier(criterion='entropy', \n",
    "        max_depth=7, min_samples_leaf=5).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN (K Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 모형결합 (Ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 취합 방법론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다수결 (Majority voting)\n",
    "\n",
    "# 취합할 모델 생성\n",
    "model1 = LinearDiscriminantAnalysis(n_components=3, solver=\"svd\", store_covariance=True)\n",
    "model2 = QuadraticDiscriminantAnalysis()\n",
    "model3 = GaussianNB()\n",
    "model4 = MultinomialNB()\n",
    "\n",
    "# ensemble 생성\n",
    "ensemble = VotingClassifier(estimators=[('lda', model1), ('qda', model2), ('gnb', model3), ('mul', model4)], \n",
    "                            voting='soft', weights=[1, 1, 1, 1])\n",
    "\n",
    "predict_proba = [c.fit(X_train, y_train).predict_proba(X_test) for c in (model1, model2, model3, model4, ensemble)]\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[4][i])) # ensemble index\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배깅 (Bagging)\n",
    "model1 = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "model2 = BaggingClassifier(DecisionTreeClassifier(), bootstrap_features=True, random_state=0).fit(X_train, y_train)\n",
    "predict_proba = model2.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest)\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=10, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 부스팅 방법론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이다 부스트 (Ada Boost)\n",
    "model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5, random_state=0), \n",
    "                               algorithm=\"SAMME\", n_estimators=100).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그레디언트 부스트 (Gradient Boost)\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# XG boost\n",
    "model = xgboost.XGBClassifier(n_estimators=100, max_depth=2).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 판별함수 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼셉트론 (Perceptron) - perceptron\n",
    "model = Perceptron(max_iter=500, eta0=0.1, random_state=1).fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼셉트론 (Perceptron) - SGD\n",
    "model = SGDClassifier(loss=\"hinge\", max_iter=3, random_state=1).fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서포트 벡터 머신 (Support Vector Machine) - linear\n",
    "model = SVC(kernel='linear').fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서포트 벡터 머신 (Support Vector Machine) - 다항 커널 (Polynomial Kernel)\n",
    "model = SVC(kernel=\"poly\", degree=2, gamma=1, coef0=0).fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서포트 벡터 머신 (Support Vector Machine) - RBF(Radial Basis Function)\n",
    "model = SVC(kernel=\"rbf\").fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서포트 벡터 머신 (Support Vector Machine) - 시그모이드 커널 (Sigmoid Kernel)\n",
    "model = SVC(kernel=\"sigmoid\", gamma=2, coef0=2).fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['win', 'lose', 'draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 (Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Validation curve\n",
    "- GridSearchCV\n",
    "- ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confusion Matrix\n",
    "- ROC Curve\n",
    "- AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ROC (Receiver Operator Characteristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X = X_train\n",
    "y = label_binarize(y_train, [0, 1, 2])\n",
    "\n",
    "# ROC curve\n",
    "fpr = [None] * 3\n",
    "tpr = [None] * 3\n",
    "thr = [None] * 3\n",
    "\n",
    "for i in range(3):\n",
    "    model = clf.fit(X, y[:, i])\n",
    "    fpr[i], tpr[i], thr[i] = roc_curve(y[:, i], model.predict_proba(X)[:, 1])\n",
    "    plt.plot(fpr[i], tpr[i])\n",
    "\n",
    "plt.xlabel('False Positive Rate (Fall-Out)')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 AUC (Area Under the Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "auc(fpr[0], tpr[0]), auc(fpr[1], tpr[1]), auc(fpr[2], tpr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
