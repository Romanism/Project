{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_train = train.drop(['Team', 'Result'], axis = 1)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(vif_train.values, i) for i in range(vif_train.shape[1])]\n",
    "vif[\"features\"] = vif_train.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_train = train.drop(['Team', 'Result', 'Possession', 'Touches', 'Offsides', 'Year'], axis = 1)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(vif_train.values, i) for i in range(vif_train.shape[1])]\n",
    "vif[\"features\"] = vif_train.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select columns & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "category = ['Home']\n",
    "continuous = ['SOT', 'Shots', 'Passes','Tackles', 'Clearances', 'Corners', 'Goal', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train/test data\n",
    "\n",
    "train_cols, test_cols = [], []\n",
    "\n",
    "# category\n",
    "for cat in category:\n",
    "    train_tok, test_tok = category_to_ohe(train[cat],test[cat])\n",
    "    train_cols.append(train_tok)\n",
    "    test_cols.append(test_tok)    \n",
    "\n",
    "# continuous\n",
    "for con in continuous:\n",
    "    train_cols.append(train[con].values.reshape(len(train),1))\n",
    "    test_cols.append(test[con].values.reshape(len(test),1))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack train/test data\n",
    "X_train = np.hstack(tuple(each for each in train_cols))\n",
    "X_test = np.hstack(tuple(each for each in test_cols))\n",
    "y_train = train['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 조건부 확률 모형 : 각 클래스가 정답일 조건부 확률을 계산\n",
    "\n",
    "    - 조건부 확률기반 생성모형 : 베이즈 정리를 사용\n",
    "\n",
    "        - LDA (linear discriminant analysis)\n",
    "        - QDA (Quadratic Discriminanat Analysis)\n",
    "        - 나이브 베이지안 (Naive Bayes)\n",
    "    \n",
    "    - 조건부 확률기반 판별모형 :  직접 조건부 확률 함수를 추정\n",
    "    \n",
    "        - 로지스틱 회귀 (Logistic Regression)\n",
    "        - 의사결정나무 (Descision Tree)\n",
    "        - KNN (K Nearest Neighbor)\n",
    "        \n",
    "        \n",
    "- 판별함수 모형 : 경계면을 찾아서 데이터가 어느 위치에 있는지 계산\n",
    "\n",
    "    - 퍼셉트론 (Perceptron)\n",
    "    - 서포트 벡터 머신 (Support Vector Machine)\n",
    "    - 신경망 (Neural Network)  \n",
    "    \n",
    "    \n",
    "- 모형결합 (Ensemble) : 복수의 예측모형을 결합하여 더 나은 성능을 예측하려는 시도\n",
    "\n",
    "    - 취합 방법론 : 사용할 모형의 집합이 이미 결정되어 있음\n",
    "        \n",
    "        - 다수결 (Majority voting)\n",
    "        - 배깅 (Bagging)\n",
    "        - 랜덤 포레스트 (Random Forest)\n",
    "        \n",
    "    - 부스팅 방법론 : 사용할 모형을 점진적으로 늘림\n",
    "    \n",
    "        - 에이다 부스트 (AdaBoost)\n",
    "        - 그레디언트 부스트 (Gradient Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 조건부 확률모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1 조건부 확률기반 생성 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA (linear discriminant analysis)\n",
    "model = LinearDiscriminantAnalysis(n_components=3, solver=\"svd\", \n",
    "        store_covariance=True).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDA (Quadratic Discriminanat Analysis)\n",
    "model = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive bayesian - Multinomial\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2 조건부 확률기반 판별모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression : 사용 X (종속변수가 이항분포를 따라야함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descision Tree\n",
    "model = DecisionTreeClassifier(criterion='entropy', \n",
    "        max_depth=7, min_samples_leaf=5).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN (K Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2.2 모형결합 (Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2.2.1 취합 방법론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다수결 (Majority voting)\n",
    "\n",
    "# 취합할 모델 생성\n",
    "model1 = LinearDiscriminantAnalysis(n_components=3, solver=\"svd\", store_covariance=True)\n",
    "model2 = QuadraticDiscriminantAnalysis()\n",
    "model3 = GaussianNB()\n",
    "model4 = MultinomialNB()\n",
    "\n",
    "# ensemble 생성\n",
    "ensemble = VotingClassifier(estimators=[('lda', model1), ('qda', model2), ('gnb', model3), ('mul', model4)], \n",
    "                            voting='soft', weights=[2, 4, 1, 5])\n",
    "\n",
    "predict_proba = [c.fit(X_train, y_train).predict_proba(X_test) for c in (model1, model2, model3, model4, ensemble)]\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[4][i])) # ensemble index\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배깅 (Bagging)\n",
    "model1 = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "model2 = BaggingClassifier(DecisionTreeClassifier(), bootstrap_features=True, random_state=0).fit(X_train, y_train)\n",
    "predict_proba = model2.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest)\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=8, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2.2.2 부스팅 방법론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이다 부스트 (Ada Boost)\n",
    "model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5, random_state=0), \n",
    "                               algorithm=\"SAMME\", n_estimators=300).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그레디언트 부스트 (Gradient Boost)\n",
    "model = GradientBoostingClassifier(n_estimators=1000, max_depth=5, random_state=0).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG boost\n",
    "model = xgboost.XGBClassifier(n_estimators=500, max_depth=2).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2.3 판별함수 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼셉트론 (Perceptron) - perceptron\n",
    "model = Perceptron(max_iter=500, eta0=0.1, random_state=1).fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼셉트론 (Perceptron) - SGD\n",
    "model = SGDClassifier(loss=\"hinge\", max_iter=3, random_state=1).fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서포트 벡터 머신 (Support Vector Machine) - linear\n",
    "model = SVC(kernel='linear').fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서포트 벡터 머신 (Support Vector Machine) - 다항 커널 (Polynomial Kernel)\n",
    "model = SVC(kernel=\"poly\", degree=2, gamma=1, coef0=0).fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서포트 벡터 머신 (Support Vector Machine) - RBF(Radial Basis Function)\n",
    "model = SVC(kernel=\"rbf\").fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서포트 벡터 머신 (Support Vector Machine) - 시그모이드 커널 (Sigmoid Kernel)\n",
    "model = SVC(kernel=\"sigmoid\", gamma=2, coef0=2).fit(X_train, y_train)\n",
    "predict_proba = model.predict(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 (Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grid Search / Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose parameter\n",
    "param_grid = [\n",
    "    {'n_estimators' : [10, 50, 100, 200, 300, 500, 1000], 'max_depth' : [2, 4, 6, 8, 10], \n",
    "     'min_samples_split' : [5, 10, 15, 20, 30]}]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid, cv = 5, return_train_score = True).fit(X1_train, y1_train)\n",
    "\n",
    "print('Best Parameter :\\n\\n', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation score\n",
    "clf = RandomForestClassifier(max_depth = 6, min_samples_split = 15, n_estimators = 100).fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv= 10)\n",
    "print('Corss Validation Score :\\n\\n', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Feature'] = col\n",
    "df['Importance'] = grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by = ['Importance'], ascending = False).reset_index(drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Goal', 'SOT', 'Clearances', 'Passes', 'Shots', 'Home', 'Tackles', 'Corners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "plt.pie(df['Importance'], labels = labels, autopct='%1.2f%%', shadow = True, explode = (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0))\n",
    "plt.title('Importance pieplot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest)\n",
    "clf = RandomForestClassifier(max_depth = 6, min_samples_split = 15, n_estimators = 100, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "model = RandomForestClassifier(max_depth = 6, min_samples_split = 15, n_estimators = 100).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# comparison\n",
    "y_true = test['Result']\n",
    "y_pred = []\n",
    "\n",
    "for i in range(760) :\n",
    "    y_pred.append(np.argmax(predict_proba[i]))\n",
    "\n",
    "target_names = ['Lose', 'Win', 'Draw']\n",
    "print('Confusion Matrix : \\n\\n',confusion_matrix(y_true, y_pred))\n",
    "print('\\n\\n Classification Report : \\n\\n', classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make binarize\n",
    "y0 = []\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] == 0 :\n",
    "        y0.append(1) # y가 0이면 1\n",
    "    else:\n",
    "        y0.append(0) # y가 0이 아니면 0\n",
    "    \n",
    "y1 = []\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] == 1 :\n",
    "        y1.append(1) # y가 1이면 1\n",
    "    else:\n",
    "        y1.append(0) # y가 1이 아니면 0\n",
    "        \n",
    "y2 = []\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] == 2 :\n",
    "        y2.append(1) # y가 2이면 1\n",
    "    else:\n",
    "        y2.append(0) # y가 2가 아니면 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model\n",
    "fpr1, tpr1, thresholds1 = roc_curve(y0, model.predict_proba(X_test)[:, 0])\n",
    "fpr2, tpr2, thresholds2 = roc_curve(y1, model.predict_proba(X_test)[:, 1])\n",
    "fpr3, tpr3, thresholds3 = roc_curve(y2, model.predict_proba(X_test)[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "print('ROC Curve :\\n')\n",
    "plt.plot(fpr1, tpr1, label= 'Predict Lose')\n",
    "plt.plot(fpr2, tpr2, label= 'Predict Win')\n",
    "plt.plot(fpr3, tpr3, label= 'Predict Draw')\n",
    "plt.legend()\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"random guess\")\n",
    "plt.xlabel('False Positive Rate (Fall-Out)')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('Premierleague Win/Lose Prediction')\n",
    "plt.show()\n",
    "\n",
    "print('AUC Score :\\n\\n', auc(fpr1, tpr1), auc(fpr2, tpr2), auc(fpr3, tpr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC score\n",
    "auc(fpr1, tpr1), auc(fpr2, tpr2), auc(fpr3, tpr3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
