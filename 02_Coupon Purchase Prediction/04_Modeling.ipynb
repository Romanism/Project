{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID_hash</th>\n",
       "      <th>COUPON_ID_hash</th>\n",
       "      <th>CAPSULE_TEXT</th>\n",
       "      <th>GENRE_NAME</th>\n",
       "      <th>SEX_ID</th>\n",
       "      <th>USABLE_DATE_MON</th>\n",
       "      <th>USABLE_DATE_TUE</th>\n",
       "      <th>USABLE_DATE_WED</th>\n",
       "      <th>USABLE_DATE_THU</th>\n",
       "      <th>USABLE_DATE_FRI</th>\n",
       "      <th>...</th>\n",
       "      <th>REG_month</th>\n",
       "      <th>REG_weekday</th>\n",
       "      <th>REG_hour</th>\n",
       "      <th>PRICE_RATE</th>\n",
       "      <th>CATALOG_PRICE</th>\n",
       "      <th>DISCOUNT_PRICE</th>\n",
       "      <th>DISPPERIOD</th>\n",
       "      <th>VALIDPERIOD</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PURCHASE_FLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2517201</th>\n",
       "      <td>5fc8a0b419f579e539d28c63f3d44b7b</td>\n",
       "      <td>5febdd370f0f8e64b9be29b418ab06c5</td>\n",
       "      <td>Spa</td>\n",
       "      <td>Spa</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>36800</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>178.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517202</th>\n",
       "      <td>5fc8a0b419f579e539d28c63f3d44b7b</td>\n",
       "      <td>5febdd370f0f8e64b9be29b418ab06c5</td>\n",
       "      <td>Spa</td>\n",
       "      <td>Spa</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>36800</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>178.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517203</th>\n",
       "      <td>5fc8a0b419f579e539d28c63f3d44b7b</td>\n",
       "      <td>5febdd370f0f8e64b9be29b418ab06c5</td>\n",
       "      <td>Spa</td>\n",
       "      <td>Spa</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>36800</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>178.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517204</th>\n",
       "      <td>295ce0aacf52e06ecde42ae6b386aef4</td>\n",
       "      <td>7f7f124e5b2a82e1dd3453d21b3eba49</td>\n",
       "      <td>Spa</td>\n",
       "      <td>Spa</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>57</td>\n",
       "      <td>10500</td>\n",
       "      <td>4500</td>\n",
       "      <td>2</td>\n",
       "      <td>179.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517205</th>\n",
       "      <td>e497d37b6d8b78d3382177f43a9d22a6</td>\n",
       "      <td>e94cbaf8b9848ad2c6b5bc243965f7c8</td>\n",
       "      <td>Hair salon</td>\n",
       "      <td>Hair salon</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>61</td>\n",
       "      <td>15330</td>\n",
       "      <td>5970</td>\n",
       "      <td>2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             USER_ID_hash                    COUPON_ID_hash  \\\n",
       "2517201  5fc8a0b419f579e539d28c63f3d44b7b  5febdd370f0f8e64b9be29b418ab06c5   \n",
       "2517202  5fc8a0b419f579e539d28c63f3d44b7b  5febdd370f0f8e64b9be29b418ab06c5   \n",
       "2517203  5fc8a0b419f579e539d28c63f3d44b7b  5febdd370f0f8e64b9be29b418ab06c5   \n",
       "2517204  295ce0aacf52e06ecde42ae6b386aef4  7f7f124e5b2a82e1dd3453d21b3eba49   \n",
       "2517205  e497d37b6d8b78d3382177f43a9d22a6  e94cbaf8b9848ad2c6b5bc243965f7c8   \n",
       "\n",
       "        CAPSULE_TEXT  GENRE_NAME SEX_ID  USABLE_DATE_MON  USABLE_DATE_TUE  \\\n",
       "2517201          Spa         Spa      f              1.0              1.0   \n",
       "2517202          Spa         Spa      f              1.0              1.0   \n",
       "2517203          Spa         Spa      f              1.0              1.0   \n",
       "2517204          Spa         Spa      f              1.0              1.0   \n",
       "2517205   Hair salon  Hair salon      f              0.0              1.0   \n",
       "\n",
       "         USABLE_DATE_WED  USABLE_DATE_THU  USABLE_DATE_FRI      ...       \\\n",
       "2517201              1.0              1.0              1.0      ...        \n",
       "2517202              1.0              1.0              1.0      ...        \n",
       "2517203              1.0              1.0              1.0      ...        \n",
       "2517204              1.0              1.0              0.0      ...        \n",
       "2517205              1.0              1.0              1.0      ...        \n",
       "\n",
       "         REG_month  REG_weekday  REG_hour  PRICE_RATE CATALOG_PRICE  \\\n",
       "2517201          9            0         0          73         36800   \n",
       "2517202          9            0         0          73         36800   \n",
       "2517203          9            0         0          73         36800   \n",
       "2517204         11            3        21          57         10500   \n",
       "2517205         10            4        23          61         15330   \n",
       "\n",
       "        DISCOUNT_PRICE DISPPERIOD  VALIDPERIOD  AGE  PURCHASE_FLG  \n",
       "2517201           9800          3        178.0   39             0  \n",
       "2517202           9800          3        178.0   39             0  \n",
       "2517203           9800          3        178.0   39             0  \n",
       "2517204           4500          2        179.0   25             1  \n",
       "2517205           5970          2         67.0   53             1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Lebel Encoder\n",
    "ls = ['CAPSULE_TEXT', 'GENRE_NAME', 'SEX_ID', 'large_area_name', 'ken_name', 'small_area_name']\n",
    "\n",
    "for i in range(len(ls)):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[ls[i]])\n",
    "    col = le.transform(train[ls[i]])\n",
    "    train[ls[i]] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Lebel Encoder\n",
    "ls = ['CAPSULE_TEXT', 'GENRE_NAME', 'SEX_ID', 'large_area_name', 'ken_name', 'small_area_name']\n",
    "\n",
    "for i in range(len(ls)):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(test[ls[i]])\n",
    "    col = le.transform(test[ls[i]])\n",
    "    test[ls[i]] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID_hash</th>\n",
       "      <th>COUPON_ID_hash</th>\n",
       "      <th>CAPSULE_TEXT</th>\n",
       "      <th>GENRE_NAME</th>\n",
       "      <th>SEX_ID</th>\n",
       "      <th>USABLE_DATE_MON</th>\n",
       "      <th>USABLE_DATE_TUE</th>\n",
       "      <th>USABLE_DATE_WED</th>\n",
       "      <th>USABLE_DATE_THU</th>\n",
       "      <th>USABLE_DATE_FRI</th>\n",
       "      <th>...</th>\n",
       "      <th>REG_month</th>\n",
       "      <th>REG_weekday</th>\n",
       "      <th>REG_hour</th>\n",
       "      <th>PRICE_RATE</th>\n",
       "      <th>CATALOG_PRICE</th>\n",
       "      <th>DISCOUNT_PRICE</th>\n",
       "      <th>DISPPERIOD</th>\n",
       "      <th>VALIDPERIOD</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PURCHASE_FLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2517201</th>\n",
       "      <td>5fc8a0b419f579e539d28c63f3d44b7b</td>\n",
       "      <td>5febdd370f0f8e64b9be29b418ab06c5</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>36800</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>178.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517202</th>\n",
       "      <td>5fc8a0b419f579e539d28c63f3d44b7b</td>\n",
       "      <td>5febdd370f0f8e64b9be29b418ab06c5</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>36800</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>178.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517203</th>\n",
       "      <td>5fc8a0b419f579e539d28c63f3d44b7b</td>\n",
       "      <td>5febdd370f0f8e64b9be29b418ab06c5</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>36800</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>178.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517204</th>\n",
       "      <td>295ce0aacf52e06ecde42ae6b386aef4</td>\n",
       "      <td>7f7f124e5b2a82e1dd3453d21b3eba49</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>57</td>\n",
       "      <td>10500</td>\n",
       "      <td>4500</td>\n",
       "      <td>2</td>\n",
       "      <td>179.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517205</th>\n",
       "      <td>e497d37b6d8b78d3382177f43a9d22a6</td>\n",
       "      <td>e94cbaf8b9848ad2c6b5bc243965f7c8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>61</td>\n",
       "      <td>15330</td>\n",
       "      <td>5970</td>\n",
       "      <td>2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             USER_ID_hash                    COUPON_ID_hash  \\\n",
       "2517201  5fc8a0b419f579e539d28c63f3d44b7b  5febdd370f0f8e64b9be29b418ab06c5   \n",
       "2517202  5fc8a0b419f579e539d28c63f3d44b7b  5febdd370f0f8e64b9be29b418ab06c5   \n",
       "2517203  5fc8a0b419f579e539d28c63f3d44b7b  5febdd370f0f8e64b9be29b418ab06c5   \n",
       "2517204  295ce0aacf52e06ecde42ae6b386aef4  7f7f124e5b2a82e1dd3453d21b3eba49   \n",
       "2517205  e497d37b6d8b78d3382177f43a9d22a6  e94cbaf8b9848ad2c6b5bc243965f7c8   \n",
       "\n",
       "         CAPSULE_TEXT  GENRE_NAME  SEX_ID  USABLE_DATE_MON  USABLE_DATE_TUE  \\\n",
       "2517201            21          12       0              1.0              1.0   \n",
       "2517202            21          12       0              1.0              1.0   \n",
       "2517203            21          12       0              1.0              1.0   \n",
       "2517204            21          12       0              1.0              1.0   \n",
       "2517205             8           4       0              0.0              1.0   \n",
       "\n",
       "         USABLE_DATE_WED  USABLE_DATE_THU  USABLE_DATE_FRI      ...       \\\n",
       "2517201              1.0              1.0              1.0      ...        \n",
       "2517202              1.0              1.0              1.0      ...        \n",
       "2517203              1.0              1.0              1.0      ...        \n",
       "2517204              1.0              1.0              0.0      ...        \n",
       "2517205              1.0              1.0              1.0      ...        \n",
       "\n",
       "         REG_month  REG_weekday  REG_hour  PRICE_RATE  CATALOG_PRICE  \\\n",
       "2517201          9            0         0          73          36800   \n",
       "2517202          9            0         0          73          36800   \n",
       "2517203          9            0         0          73          36800   \n",
       "2517204         11            3        21          57          10500   \n",
       "2517205         10            4        23          61          15330   \n",
       "\n",
       "         DISCOUNT_PRICE  DISPPERIOD  VALIDPERIOD  AGE  PURCHASE_FLG  \n",
       "2517201            9800           3        178.0   39             0  \n",
       "2517202            9800           3        178.0   39             0  \n",
       "2517203            9800           3        178.0   39             0  \n",
       "2517204            4500           2        179.0   25             1  \n",
       "2517205            5970           2         67.0   53             1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID_hash</th>\n",
       "      <th>COUPON_ID_hash</th>\n",
       "      <th>CAPSULE_TEXT</th>\n",
       "      <th>GENRE_NAME</th>\n",
       "      <th>SEX_ID</th>\n",
       "      <th>USABLE_DATE_MON</th>\n",
       "      <th>USABLE_DATE_TUE</th>\n",
       "      <th>USABLE_DATE_WED</th>\n",
       "      <th>USABLE_DATE_THU</th>\n",
       "      <th>USABLE_DATE_FRI</th>\n",
       "      <th>...</th>\n",
       "      <th>REG_year</th>\n",
       "      <th>REG_month</th>\n",
       "      <th>REG_weekday</th>\n",
       "      <th>REG_hour</th>\n",
       "      <th>PRICE_RATE</th>\n",
       "      <th>CATALOG_PRICE</th>\n",
       "      <th>DISCOUNT_PRICE</th>\n",
       "      <th>DISPPERIOD</th>\n",
       "      <th>VALIDPERIOD</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7090625</th>\n",
       "      <td>2f0a2f36a9f63b6ba2fa3a7e53bef906</td>\n",
       "      <td>f9c657ce7ca80b3766ced3a9a3c709bb</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>28000</td>\n",
       "      <td>14000</td>\n",
       "      <td>4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090626</th>\n",
       "      <td>6ae7811a9c7c58546d6a1567ab098c21</td>\n",
       "      <td>f9c657ce7ca80b3766ced3a9a3c709bb</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>28000</td>\n",
       "      <td>14000</td>\n",
       "      <td>4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090627</th>\n",
       "      <td>a417308c6a79ae0d86976401ec2e3b04</td>\n",
       "      <td>f9c657ce7ca80b3766ced3a9a3c709bb</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>28000</td>\n",
       "      <td>14000</td>\n",
       "      <td>4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090628</th>\n",
       "      <td>4937ec1c86e71d901c4ccc0357cff0b1</td>\n",
       "      <td>f9c657ce7ca80b3766ced3a9a3c709bb</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>28000</td>\n",
       "      <td>14000</td>\n",
       "      <td>4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090629</th>\n",
       "      <td>280f0cedda5c4b171ee6245889659571</td>\n",
       "      <td>f9c657ce7ca80b3766ced3a9a3c709bb</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>28000</td>\n",
       "      <td>14000</td>\n",
       "      <td>4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             USER_ID_hash                    COUPON_ID_hash  \\\n",
       "7090625  2f0a2f36a9f63b6ba2fa3a7e53bef906  f9c657ce7ca80b3766ced3a9a3c709bb   \n",
       "7090626  6ae7811a9c7c58546d6a1567ab098c21  f9c657ce7ca80b3766ced3a9a3c709bb   \n",
       "7090627  a417308c6a79ae0d86976401ec2e3b04  f9c657ce7ca80b3766ced3a9a3c709bb   \n",
       "7090628  4937ec1c86e71d901c4ccc0357cff0b1  f9c657ce7ca80b3766ced3a9a3c709bb   \n",
       "7090629  280f0cedda5c4b171ee6245889659571  f9c657ce7ca80b3766ced3a9a3c709bb   \n",
       "\n",
       "         CAPSULE_TEXT  GENRE_NAME  SEX_ID  USABLE_DATE_MON  USABLE_DATE_TUE  \\\n",
       "7090625             7           5       0              1.0              1.0   \n",
       "7090626             7           5       1              1.0              1.0   \n",
       "7090627             7           5       0              1.0              1.0   \n",
       "7090628             7           5       0              1.0              1.0   \n",
       "7090629             7           5       0              1.0              1.0   \n",
       "\n",
       "         USABLE_DATE_WED  USABLE_DATE_THU  USABLE_DATE_FRI ...   REG_year  \\\n",
       "7090625              1.0              1.0              1.0 ...       2011   \n",
       "7090626              1.0              1.0              1.0 ...       2011   \n",
       "7090627              1.0              1.0              1.0 ...       2012   \n",
       "7090628              1.0              1.0              1.0 ...       2011   \n",
       "7090629              1.0              1.0              1.0 ...       2011   \n",
       "\n",
       "         REG_month  REG_weekday  REG_hour  PRICE_RATE  CATALOG_PRICE  \\\n",
       "7090625         12            0        15          50          28000   \n",
       "7090626          8            2         0          50          28000   \n",
       "7090627          4            3        12          50          28000   \n",
       "7090628          2            6        10          50          28000   \n",
       "7090629          2            3        15          50          28000   \n",
       "\n",
       "         DISCOUNT_PRICE  DISPPERIOD  VALIDPERIOD  AGE  \n",
       "7090625           14000           4         67.0   24  \n",
       "7090626           14000           4         67.0   41  \n",
       "7090627           14000           4         67.0   35  \n",
       "7090628           14000           4         67.0   59  \n",
       "7090629           14000           4         67.0   38  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.603343e+01</td>\n",
       "      <td>CAPSULE_TEXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.991143e+01</td>\n",
       "      <td>GENRE_NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.920396e+00</td>\n",
       "      <td>SEX_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.806329e+01</td>\n",
       "      <td>USABLE_DATE_MON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.347335e+01</td>\n",
       "      <td>USABLE_DATE_TUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.057954e+02</td>\n",
       "      <td>USABLE_DATE_WED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.367520e+02</td>\n",
       "      <td>USABLE_DATE_THU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.510812e+01</td>\n",
       "      <td>USABLE_DATE_FRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.508113e+01</td>\n",
       "      <td>USABLE_DATE_SAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.329885e+01</td>\n",
       "      <td>USABLE_DATE_SUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.049509e+01</td>\n",
       "      <td>USABLE_DATE_HOLIDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.152730e+01</td>\n",
       "      <td>USABLE_DATE_BEFORE_HOLIDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.038989e+01</td>\n",
       "      <td>large_area_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.092425e+00</td>\n",
       "      <td>ken_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.944137e+00</td>\n",
       "      <td>small_area_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.959768e+09</td>\n",
       "      <td>DISPFROM_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.396254e+02</td>\n",
       "      <td>DISPFROM_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.355234e+00</td>\n",
       "      <td>DISPFROM_weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.528136e+03</td>\n",
       "      <td>DISPFROM_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.969898e+09</td>\n",
       "      <td>DISPEND_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.472590e+02</td>\n",
       "      <td>DISPEND_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.766961e+00</td>\n",
       "      <td>DISPEND_weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.899069e+03</td>\n",
       "      <td>DISPEND_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.473608e+07</td>\n",
       "      <td>REG_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.855452e+00</td>\n",
       "      <td>REG_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.263598e+00</td>\n",
       "      <td>REG_weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.536256e+00</td>\n",
       "      <td>REG_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.303744e+01</td>\n",
       "      <td>PRICE_RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.043242e+01</td>\n",
       "      <td>CATALOG_PRICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.111342e+01</td>\n",
       "      <td>DISCOUNT_PRICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.784566e+00</td>\n",
       "      <td>DISPPERIOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.268797e+01</td>\n",
       "      <td>VALIDPERIOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.981162e+01</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VIF Factor                    features\n",
       "0   7.603343e+01                CAPSULE_TEXT\n",
       "1   5.991143e+01                  GENRE_NAME\n",
       "2   1.920396e+00                      SEX_ID\n",
       "3   3.806329e+01             USABLE_DATE_MON\n",
       "4   5.347335e+01             USABLE_DATE_TUE\n",
       "5   1.057954e+02             USABLE_DATE_WED\n",
       "6   1.367520e+02             USABLE_DATE_THU\n",
       "7   4.510812e+01             USABLE_DATE_FRI\n",
       "8   2.508113e+01             USABLE_DATE_SAT\n",
       "9   2.329885e+01             USABLE_DATE_SUN\n",
       "10  3.049509e+01         USABLE_DATE_HOLIDAY\n",
       "11  3.152730e+01  USABLE_DATE_BEFORE_HOLIDAY\n",
       "12  1.038989e+01             large_area_name\n",
       "13  7.092425e+00                    ken_name\n",
       "14  3.944137e+00             small_area_name\n",
       "15  6.959768e+09               DISPFROM_year\n",
       "16  6.396254e+02              DISPFROM_month\n",
       "17  3.355234e+00            DISPFROM_weekday\n",
       "18  2.528136e+03               DISPFROM_hour\n",
       "19  6.969898e+09                DISPEND_year\n",
       "20  6.472590e+02               DISPEND_month\n",
       "21  3.766961e+00             DISPEND_weekday\n",
       "22  6.899069e+03                DISPEND_hour\n",
       "23  2.473608e+07                    REG_year\n",
       "24  8.855452e+00                   REG_month\n",
       "25  3.263598e+00                 REG_weekday\n",
       "26  6.536256e+00                    REG_hour\n",
       "27  4.303744e+01                  PRICE_RATE\n",
       "28  1.043242e+01               CATALOG_PRICE\n",
       "29  1.111342e+01              DISCOUNT_PRICE\n",
       "30  4.784566e+00                  DISPPERIOD\n",
       "31  1.268797e+01                 VALIDPERIOD\n",
       "32  1.981162e+01                         AGE"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "train_vif = train.drop(['USER_ID_hash', 'COUPON_ID_hash', 'PURCHASE_FLG'], axis = 1)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(train_vif.values, i) for i in range(train_vif.shape[1])]\n",
    "vif[\"features\"] = train_vif.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['GENRE_NAME', 'USABLE_DATE_MON', 'USABLE_DATE_TUE', 'USABLE_DATE_WED', 'USABLE_DATE_THU', \n",
    "                    'USABLE_DATE_FRI', 'USABLE_DATE_SAT', 'USABLE_DATE_SUN', 'DISPFROM_year', 'DISPFROM_month', \n",
    "                    'DISPFROM_hour', 'DISPEND_year', 'DISPEND_month', 'DISPEND_hour', 'REG_year',\n",
    "                    'USABLE_DATE_BEFORE_HOLIDAY', 'PRICE_RATE'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.624585</td>\n",
       "      <td>CAPSULE_TEXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.910976</td>\n",
       "      <td>SEX_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.768617</td>\n",
       "      <td>USABLE_DATE_HOLIDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.300717</td>\n",
       "      <td>large_area_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.564098</td>\n",
       "      <td>ken_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.891159</td>\n",
       "      <td>small_area_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.176721</td>\n",
       "      <td>DISPFROM_weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.524970</td>\n",
       "      <td>DISPEND_weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.245931</td>\n",
       "      <td>REG_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.165578</td>\n",
       "      <td>REG_weekday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.097317</td>\n",
       "      <td>REG_hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.891258</td>\n",
       "      <td>CATALOG_PRICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.166476</td>\n",
       "      <td>DISCOUNT_PRICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.768998</td>\n",
       "      <td>DISPPERIOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.962971</td>\n",
       "      <td>VALIDPERIOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.320705</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF Factor             features\n",
       "0     3.624585         CAPSULE_TEXT\n",
       "1     1.910976               SEX_ID\n",
       "2    12.768617  USABLE_DATE_HOLIDAY\n",
       "3     9.300717      large_area_name\n",
       "4     6.564098             ken_name\n",
       "5     3.891159      small_area_name\n",
       "6     3.176721     DISPFROM_weekday\n",
       "7     3.524970      DISPEND_weekday\n",
       "8     4.245931            REG_month\n",
       "9     3.165578          REG_weekday\n",
       "10    6.097317             REG_hour\n",
       "11    6.891258        CATALOG_PRICE\n",
       "12    7.166476       DISCOUNT_PRICE\n",
       "13    2.768998           DISPPERIOD\n",
       "14    9.962971          VALIDPERIOD\n",
       "15   15.320705                  AGE"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vif = train.drop(['USER_ID_hash', 'COUPON_ID_hash', 'PURCHASE_FLG'], axis = 1)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(train_vif.values, i) for i in range(train_vif.shape[1])]\n",
    "vif[\"features\"] = train_vif.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select columns & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USER_ID_hash', 'COUPON_ID_hash', 'CAPSULE_TEXT', 'SEX_ID',\n",
       "       'USABLE_DATE_HOLIDAY', 'large_area_name', 'ken_name', 'small_area_name',\n",
       "       'DISPFROM_weekday', 'DISPEND_weekday', 'REG_month', 'REG_weekday',\n",
       "       'REG_hour', 'CATALOG_PRICE', 'DISCOUNT_PRICE', 'DISPPERIOD',\n",
       "       'VALIDPERIOD', 'AGE', 'PURCHASE_FLG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USER_ID_hash', 'COUPON_ID_hash', 'CAPSULE_TEXT', 'GENRE_NAME',\n",
       "       'SEX_ID', 'USABLE_DATE_MON', 'USABLE_DATE_TUE', 'USABLE_DATE_WED',\n",
       "       'USABLE_DATE_THU', 'USABLE_DATE_FRI', 'USABLE_DATE_SAT',\n",
       "       'USABLE_DATE_SUN', 'USABLE_DATE_HOLIDAY', 'USABLE_DATE_BEFORE_HOLIDAY',\n",
       "       'large_area_name', 'ken_name', 'small_area_name', 'DISPFROM_year',\n",
       "       'DISPFROM_month', 'DISPFROM_weekday', 'DISPFROM_hour', 'DISPEND_year',\n",
       "       'DISPEND_month', 'DISPEND_weekday', 'DISPEND_hour', 'REG_year',\n",
       "       'REG_month', 'REG_weekday', 'REG_hour', 'PRICE_RATE', 'CATALOG_PRICE',\n",
       "       'DISCOUNT_PRICE', 'DISPPERIOD', 'VALIDPERIOD', 'AGE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "category = ['CAPSULE_TEXT', 'SEX_ID', 'USABLE_DATE_HOLIDAY', 'large_area_name', \n",
    "            'ken_name', 'small_area_name', 'DISPFROM_weekday', 'DISPEND_weekday', 'REG_month', \n",
    "            'REG_weekday', 'REG_hour']\n",
    "continuous = ['CATALOG_PRICE', 'DISCOUNT_PRICE', 'DISPPERIOD', 'VALIDPERIOD', 'AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make train/test data\n",
    "\n",
    "train_cols, test_cols = [], []\n",
    "\n",
    "# category\n",
    "for cat in category:\n",
    "    train_tok, test_tok = category_to_ohe(train[cat],test[cat])\n",
    "    train_cols.append(train_tok)\n",
    "    test_cols.append(test_tok)    \n",
    "\n",
    "# continuous\n",
    "for con in continuous:\n",
    "    train_cols.append(train[con].values.reshape(len(train),1))\n",
    "    test_cols.append(test[con].values.reshape(len(test),1))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack train/test data\n",
    "X_train = np.hstack(tuple(each for each in train_cols))\n",
    "X_test = np.hstack(tuple(each for each in test_cols))\n",
    "y_train = train['PURCHASE_FLG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.,   0.,   1., ...,   4., 126.,  25.],\n",
       "       [  3.,   0.,   1., ...,   4., 126.,  25.],\n",
       "       [  3.,   0.,   1., ...,   4., 126.,  25.],\n",
       "       ...,\n",
       "       [ 21.,   0.,   1., ...,   3., 178.,  39.],\n",
       "       [ 21.,   0.,   1., ...,   2., 179.,  25.],\n",
       "       [  8.,   0.,   1., ...,   2.,  67.,  53.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.,   0.,   1., ...,   4., 118.,  25.],\n",
       "       [  3.,   0.,   1., ...,   4., 118.,  34.],\n",
       "       [  3.,   1.,   1., ...,   4., 118.,  41.],\n",
       "       ...,\n",
       "       [  7.,   0.,   1., ...,   4.,  67.,  35.],\n",
       "       [  7.,   0.,   1., ...,   4.,  67.,  59.],\n",
       "       [  7.,   0.,   1., ...,   4.,  67.,  38.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2517201    0\n",
       "2517202    0\n",
       "2517203    0\n",
       "2517204    1\n",
       "2517205    1\n",
       "Name: PURCHASE_FLG, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 조건부 확률 모형 : 각 클래스가 정답일 조건부 확률을 계산\n",
    "\n",
    "    - 조건부 확률기반 생성모형 : 베이즈 정리를 사용\n",
    "\n",
    "        - LDA (linear discriminant analysis)\n",
    "        - QDA (Quadratic Discriminanat Analysis)\n",
    "        - 나이브 베이지안 (Naive Bayes)\n",
    "    \n",
    "    - 조건부 확률기반 판별모형 :  직접 조건부 확률 함수를 추정\n",
    "    \n",
    "        - 로지스틱 회귀 (Logistic Regression)\n",
    "        - 의사결정나무 (Descision Tree)\n",
    "        - KNN (K Nearest Neighbor)\n",
    "        \n",
    "        \n",
    "- 판별함수 모형 : 경계면을 찾아서 데이터가 어느 위치에 있는지 계산\n",
    "\n",
    "    - 퍼셉트론 (Perceptron)\n",
    "    - 서포트 벡터 머신 (Support Vector Machine)\n",
    "    - 신경망 (Neural Network)  \n",
    "    \n",
    "    \n",
    "- 모형결합 (Ensemble) : 복수의 예측모형을 결합하여 더 나은 성능을 예측하려는 시도\n",
    "\n",
    "    - 취합 방법론 : 사용할 모형의 집합이 이미 결정되어 있음\n",
    "        \n",
    "        - 다수결 (Majority voting)\n",
    "        - 배깅 (Bagging)\n",
    "        - 랜덤 포레스트 (Random Forest)\n",
    "        \n",
    "    - 부스팅 방법론 : 사용할 모형을 점진적으로 늘림\n",
    "    \n",
    "        - 에이다 부스트 (AdaBoost)\n",
    "        - 그레디언트 부스트 (Gradient Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 조건부 확률모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1 조건부 확률기반 생성 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA (linear discriminant analysis) (score : 0.000610)\n",
    "model = LinearDiscriminantAnalysis(n_components=3, solver=\"svd\", \n",
    "        store_covariance=True).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/LDA.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDA (Quadratic Discriminanat Analysis) (score : 0.000427)\n",
    "model = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/QDA.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Naive bayesian - Multinomial (score : 0.000210)\n",
    "model = MultinomialNB(alpha = 0.001).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/NBM.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2 조건부 확률기반 판별모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (0.001174)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=500).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/Logistic.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descision Tree (0.001008)\n",
    "model = DecisionTreeClassifier(criterion='entropy', \n",
    "        max_depth=7, min_samples_leaf=5).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/DT.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 모형결합 (Ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1 취합 방법론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배깅 (Bagging) (score : 0.000329)\n",
    "model1 = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "model2 = BaggingClassifier(DecisionTreeClassifier(), bootstrap_features=True, random_state=0).fit(X_train, y_train)\n",
    "predict_proba = model2.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/Bagging.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001720)\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=5, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2 부스팅 방법론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이다 부스트 (Ada Boost) (score : 0.001066)\n",
    "model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5, random_state=0), \n",
    "                               algorithm=\"SAMME\", n_estimators=300).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/Ada.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그레디언트 부스트 (Gradient Boost) (score : 0.000999)\n",
    "model = GradientBoostingClassifier(n_estimators=200, max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/Gradient.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001422)\n",
    "model = xgboost.XGBClassifier(n_estimators=200, max_depth=3).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XG1.csv',  header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modeling 심화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001095) \n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=3, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(300,3).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001303)\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=4, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(300,4).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001317)\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=5, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(300,5).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001776)\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=6, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(300,6).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001840)\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=7, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(300,7).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.002037)\n",
    "clf = RandomForestClassifier(n_estimators=400, max_depth=3, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(400,3).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001044)\n",
    "clf = RandomForestClassifier(n_estimators=400, max_depth=4, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(400,4).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001406)\n",
    "clf = RandomForestClassifier(n_estimators=400, max_depth=5, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(400,5).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.000869)\n",
    "clf = RandomForestClassifier(n_estimators=400, max_depth=6, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(400,6).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001186)\n",
    "clf = RandomForestClassifier(n_estimators=400, max_depth=7, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(400,7).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001134)\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=3, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(500,3).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.000960)\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=4, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(500,4).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001478)\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=5, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(500,5).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.000941)\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=6, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(500,6).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001625)\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=7, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(500,7).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.000930)\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=3, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(1000,3).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001245)\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=4, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(1000,4).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001208)\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=5, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(1000,5).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.002595)\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=6, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(1000,6).csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트 (RandomForest) (score : 0.001146)\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=7, min_samples_split = 10, criterion = 'entropy')\n",
    "model = clf.fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/RandomForest(1000,7).csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001022)\n",
    "model = xgboost.XGBClassifier(n_estimators=100, max_depth=3).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(100,3).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001648)\n",
    "model = xgboost.XGBClassifier(n_estimators=100, max_depth=4).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(100,4).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001057)\n",
    "model = xgboost.XGBClassifier(n_estimators=100, max_depth=5).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(100,5).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001422)\n",
    "model = xgboost.XGBClassifier(n_estimators=200, max_depth=3).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(200,3).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001051)\n",
    "model = xgboost.XGBClassifier(n_estimators=200, max_depth=4).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(200,4).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001238)\n",
    "model = xgboost.XGBClassifier(n_estimators=200, max_depth=5).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(200,5).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001915)\n",
    "model = xgboost.XGBClassifier(n_estimators=300, max_depth=3).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(300,3).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001861)\n",
    "model = xgboost.XGBClassifier(n_estimators=300, max_depth=4).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(300,4).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001542)\n",
    "model = xgboost.XGBClassifier(n_estimators=300, max_depth=5).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(300,5).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001734)\n",
    "model = xgboost.XGBClassifier(n_estimators=400, max_depth=3).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(400,3).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.000903)\n",
    "model = xgboost.XGBClassifier(n_estimators=400, max_depth=4).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(400,4).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001314)\n",
    "model = xgboost.XGBClassifier(n_estimators=400, max_depth=5).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(400,5).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.002329)\n",
    "model = xgboost.XGBClassifier(n_estimators=500, max_depth=3).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(500,3).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001371)\n",
    "model = xgboost.XGBClassifier(n_estimators=500, max_depth=4).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(500,4).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XG boost (score : 0.001596)\n",
    "model = xgboost.XGBClassifier(n_estimators=500, max_depth=5).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(500,5).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG boost (score : 0.000962)\n",
    "model = xgboost.XGBClassifier(n_estimators=1000, max_depth=3).fit(X_train, y_train)\n",
    "predict_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Top 10 Coupon\n",
    "pos_idx = np.where(model.classes_ == True)[0][0]\n",
    "test['predict'] = predict_proba[:, pos_idx]\n",
    "top10_coupon = test.groupby('USER_ID_hash').apply(top_merge)\n",
    "top10_coupon.name = 'PURCHASED_COUPONS'\n",
    "top10_coupon.to_csv('modeling/XGBoost(1000,3).csv',  header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
